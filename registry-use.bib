
@article{corduneanu-huci_what_2022,
	title = {What, {Where}, {Who}, and {Why}? {An} {Empirical} {Investigation} of {Positionality} in {Political} {Science} {Field} {Experiments}},
	volume = {55},
	issn = {1049-0965, 1537-5935},
	shorttitle = {What, {Where}, {Who}, and {Why}?},
	url = {https://www.cambridge.org/core/product/identifier/S104909652200066X/type/journal_article},
	doi = {10.1017/S104909652200066X},
	language = {en},
	number = {4},
	urldate = {2023-11-30},
	journal = {PS: Political Science \& Politics},
	author = {Corduneanu-Huci, Cristina and Dorsch, Michael T. and Maarek, Paul},
	month = oct,
	year = {2022},
	note = {tex.ids= zotero-9598},
	pages = {741--748},
}

@article{miguel_evidence_2021,
	title = {Evidence on {Research} {Transparency} in {Economics}},
	volume = {35},
	issn = {0895-3309},
	url = {https://www.aeaweb.org/articles?id=10.1257/jep.35.3.193},
	doi = {10.1257/jep.35.3.193},
	abstract = {A decade ago, the term "research transparency" was not on economists' radar screen, but in a few short years a scholarly movement has emerged to bring new open 
science practices, tools and norms into the mainstream of our discipline. The goal of this article is to lay out the evidence on the adoption of these approaches—in three 
specific areas: open data, pre-registration and pre-analysis plans, and journal policies—and, more tentatively, begin to assess their impacts on the quality and credibility of 
economics research. The evidence to date indicates that economics (and related quantitative social science fields) are in a period of rapid transition toward new 
transparency-enhancing norms. While solid data on the benefits of these practices in economics is still limited, in part due to their relatively recent adoption, there is 
growing reason to believe that critics' worst fears regarding onerous adoption costs have not been realized. Finally, the article presents a set of frontier questions and 
potential innovations.},
	language = {en},
	number = {3},
	urldate = {2023-11-30},
	journal = {Journal of Economic Perspectives},
	author = {Miguel, Edward},
	month = aug,
	year = {2021},
	keywords = {Computer Programs: General, Computer Programs: General, Higher Education, Market for Economists, Hypothesis Testing: General, Data Collection and Data Estimation Methodology, Research Institutions, Role of Economics, Role of Economics, Role of Economists},
	pages = {193--214},
}

@inproceedings{murtagh-white_learning_2023,
	title = {Learning from the {Evidence}: {Impact} {Evaluations}, {Ontology} and {Policy}},
	shorttitle = {Learning from the {Evidence}},
	url = {https://ieeexplore.ieee.org/abstract/document/10066824},
	doi = {10.1109/ICSC56153.2023.00023},
	abstract = {In the past two decades, the use of Randomised Controlled Trials (RCTs) in economics and international development has grown, providing policymakers and researchers with new insight into what interventions work in improving people’s welfare. This paper proposes a novel ontology based on the OWL framework that describes the results, methods and themes of RCTs in social science and policy. The ontology was evaluated using data from the American Economic Association Registry of RCTs, the International Initiative for Impact Evaluation’s evidence hub and the World Bank; it was found to be effective at filtering relevant studies but less useful in pooling treatment results due to a lack of source data.},
	urldate = {2023-11-30},
	booktitle = {2023 {IEEE} 17th {International} {Conference} on {Semantic} {Computing} ({ICSC})},
	author = {Murtagh-White, Matt and Wall, P. J. and O’Sullivan, Declan},
	month = feb,
	year = {2023},
	note = {ISSN: 2325-6516},
	pages = {104--106},
}

@article{leight_publication_2022,
	title = {Publication {Bias} in {Randomized} {Controlled} {Trials}: {Evidence} from the {American} {Economic} {Association} {Registry}},
	shorttitle = {Publication {Bias} in {Randomized} {Controlled} {Trials}},
	url = {https://osf.io/wsxd9},
	doi = {10.17605/OSF.IO/WSXD9},
	abstract = {In recent years, the trend of preregistering randomized controlled trials in economics and related fields (e.g. political science) has accelerated rapidly, and publication requirements increasingly mandate that every published trial be pre-registered.  However, there is still scope for substantial publication bias in that large numbers of evaluations are preregistered that are never published: some may in fact not be conducted, but many are conducted but yield no published outputs, instead resulting in some other type of output (policy brief, working paper, etc.) or sometimes no public-facing output all around.  While some meta-analyses have estimated publication bias, the systematic availability of data on registered trials from the American Economic Association registry allows us to quantify how many registered trials are published; what the publication lag time is; in which form they are published (peer reviewed journal articles vs. working papers vs. other type of output) and the correlation between trial characteristics (including sample size, minimum detectable effect, presence of null effects versus statistically significant effects, etc.) and publication probability.},
	language = {en-us},
	urldate = {2023-11-30},
	author = {Leight, Jessica and Asri, Viola and Imai, Taisuke},
	month = jul,
	year = {2022},
	note = {Publisher: OSF},
}

@misc{christensen_open_2019,
	title = {Open {Science} {Practices} are on the {Rise}: {The} {State} of {Social} {Science} ({3S}) {Survey}},
	shorttitle = {Open {Science} {Practices} are on the {Rise}},
	url = {https://osf.io/preprints/metaarxiv/5rksu/},
	doi = {10.31222/osf.io/5rksu},
	abstract = {Has there been meaningful movement toward open science practices within the social sciences in recent years? Discussions about changes in practices such as posting data and pre-registering analyses have been marked by controversy—including controversy over the extent to which change has taken place. This study, based on the State of Social Science (3S) Survey, provides the first comprehensive assessment of awareness of, attitudes towards, perceived norms regarding, and adoption of open science practices within a broadly representative sample of scholars from four major social science disciplines: economics, political science, psychology, and sociology. We observe a steep increase in adoption: as of 2017, over 80\% of scholars had used at least one such practice, rising from one quarter a decade earlier. Attitudes toward research transparency are on average similar between older and younger scholars, but the pace
of change differs by field and methodology. According with theories of normal science and scientific change, the timing of increases in adoption coincides with technological innovations and institutional policies. Patterns are consistent with most scholars underestimating the trend toward open science in their discipline.},
	language = {en-us},
	urldate = {2023-11-30},
	publisher = {MetaArXiv},
	author = {Christensen, Garret and Wang, Zenan and Paluck, Elizabeth Levy and Swanson, Nicholas and Birke, David J. and Miguel, Edward and Littman, Rebecca},
	month = oct,
	year = {2019},
	keywords = {Social and Behavioral Sciences, economics, open code, open data, open science, political science, pre-analysis plan, pre-registration, psychology, reproducibility, research practice, social science, sociology, transparency},
}

@misc{ofosu_pre-analysis_2019,
	title = {Pre-analysis {Plans}: {A} {Stocktaking}},
	shorttitle = {Pre-analysis {Plans}},
	url = {https://osf.io/preprints/metaarxiv/e4pum/},
	doi = {10.31222/osf.io/e4pum},
	abstract = {The evidence-based community has championed the public registration of pre-analysis plans (PAPs) as a solution to the problem of research credibility, but without any evidence that PAPs actually bolster the credibility of research. We analyze a representative sample of 195 PAPs from the American Economic Association (AEA) and Evidence in Governance and Politics (EGAP) registration platforms to assess whether PAPs are sufficiently clear, precise and comprehensive to be able to achieve their objectives of preventing “fishing” and reducing the scope for post-hoc adjustment of research hypotheses. We also analyze a subset of 93 PAPs from projects that have resulted in publicly available papers to ascertain how faithfully they adhere to their pre-registered specifications and hypotheses. We find significant variation in the extent to which PAPs are accomplishing the goals they were designed to achieve},
	language = {en-us},
	urldate = {2023-11-30},
	publisher = {MetaArXiv},
	author = {Ofosu, George and Posner, Daniel N.},
	month = dec,
	year = {2019},
	keywords = {AEA RCT registry, EGAP registry, Economics, Political Science, SSMART, Social and Behavioral Sciences, meta-research, pre-analysis plans, registration},
}

@article{laitin_reporting_2021,
	title = {Reporting all results efficiently: {A} {RARE} proposal to open up the file drawer},
	volume = {118},
	shorttitle = {Reporting all results efficiently},
	url = {https://www.pnas.org/doi/full/10.1073/pnas.2106178118},
	doi = {10.1073/pnas.2106178118},
	abstract = {While the social sciences have made impressive progress in adopting transparent research practices that facilitate verification, replication, and reuse of materials, the problem of publication bias persists. Bias on the part of peer reviewers and journal editors, as well as the use of outdated research practices by authors, continues to skew literature toward statistically significant effects, many of which may be false positives. To mitigate this bias, we propose a framework to enable authors to report all results efficiently (RARE), with an initial focus on experimental and other prospective empirical social science research that utilizes public study registries. This framework depicts an integrated system that leverages the capacities of existing infrastructure in the form of public registries, institutional review boards, journals, and granting agencies, as well as investigators themselves, to efficiently incentivize full reporting and thereby, improve confidence in social science findings. In addition to increasing access to the results of scientific endeavors, a well-coordinated research ecosystem can prevent scholars from wasting time investigating the same questions in ways that have not worked in the past and reduce wasted funds on the part of granting agencies.},
	number = {52},
	urldate = {2023-11-30},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Laitin, David D. and Miguel, Edward and Alrababa’h, Ala’ and Bogdanoski, Aleksandar and Grant, Sean and Hoeberling, Katherine and Hyunjung Mo, Cecilia and Moore, Don A. and Vazire, Simine and Weinstein, Jeremy and Williamson, Scott},
	month = dec,
	year = {2021},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2106178118},
}

@article{abrams_research_2020,
	title = {Research {Registries}: {Facts}, {Myths}, and {Possible} {Improvements}},
	shorttitle = {Research {Registries}},
	url = {https://ideas.repec.org//p/feb/artefa/00703.html},
	abstract = {The past few decades have ushered in an experimental revolution in economics whereby scholars are now much more likely to generate their own data. While there are virtues associated with this movement, there are concomitant difficulties. Several scientific disciplines, including economics, have launched research registries in an effort to attenuate key inferential issues. This study assesses registries both empirically and theoretically, with a special focus on the AEA registry. We find that over 90\% of randomized controlled trials (RCTs) in economics do not register, only 50\% of the RCTs that register do so before the intervention begins, and the majority of these preregistrations are not detailed enough to significantly aid inference. Our empirical analysis further shows that using other scientific registries as aspirational examples is misguided, as their perceived success in tackling the main issues is largely a myth. In light of these facts, we advance a simple economic model to explore potential improvements. A key insight from the model is that removal of the (current) option to register completed RCTs could increase the fraction of trials that register. We also argue that linking IRB applications to registrations could further increase registry effectiveness.},
	language = {en},
	urldate = {2023-11-30},
	journal = {Artefactual Field Experiments},
	author = {Abrams, Eliot and Libgober, Jonathan and List, John},
	year = {2020},
	note = {Number: 00703
Publisher: The Field Experiments Website},
}

@article{corduneanu-huci_politics_2021,
	title = {The politics of experimentation: {Political} competition and randomized controlled trials},
	volume = {49},
	issn = {0147-5967},
	shorttitle = {The politics of experimentation},
	url = {https://www.sciencedirect.com/science/article/pii/S0147596720300652},
	doi = {10.1016/j.jce.2020.09.002},
	abstract = {This paper provides an analysis of how political factors affect the incidence of the evaluation of public policies, with a focus on Randomized Control Trial (RCT) experiments in international development. We argue that political environments where incumbents face greater electoral competition and smaller ruling margins are more likely to host RCT experiments. Using various data sources for the incidence of RCTs both at the cross-country level and at the sub-national level in India, we find that RCTs are more likely to occur in politically competitive jurisdictions. We employ fixed effects regressions using various estimators and an instrumental variable strategy that exploits an electoral reform in India which limited the entry of independent candidates and exogenously affected the degree of electoral competition in state-level politics. The effect seems concentrated on RCTs that have the government as a partner, suggesting that political competition has an important demand-side effect on the incidence of RCTs.},
	number = {1},
	urldate = {2023-11-30},
	journal = {Journal of Comparative Economics},
	author = {Corduneanu-Huci, Cristina and Dorsch, Michael T. and Maarek, Paul},
	month = mar,
	year = {2021},
	keywords = {Development policy, External validity, Political competition, Randomized controlled trials},
	pages = {1--21},
}

@article{buckley_role_2022,
	title = {The {Role} of {Clearinghouses} in {Promoting} {Transparent} {Research}: {A} {Methodological} {Study} of {Transparency} {Practices} for {Preventive} {Interventions}},
	volume = {23},
	issn = {1573-6695},
	url = {https://doi.org/10.1007/s11121-021-01252-5},
	doi = {10.1007/s11121-021-01252-5},
	abstract = {Transparency of research methods is vital to science, though incentives are variable, with only some journals and funders adopting transparency policies. Clearinghouses are also important stakeholders; however, to date none have implemented formal procedures that facilitate transparent research. Using data from the longest standing clearinghouse, we examine transparency practices for preventive interventions to explore the role of online clearinghouses in incentivizing researchers to make their research more transparent. We conducted a descriptive analysis of 88 evaluation reports reviewed in 2018–2019 by Blueprints for Healthy Youth Development, when the clearinghouse began checking for trial registrations, and expanded on these efforts by applying broader transparency standards to interventions eligible for an endorsement on the Blueprints website during the study period. Reports were recent, with 84\% published between 2010 and 2019. We found that few reports had data, code, or research materials that were publicly available. Meanwhile, 40\% had protocols that were registered, but only 8\% were registered prospectively, while one-quarter were registered before conducting analyses. About one-third included details in a registered protocol describing the treatment contrast and planned inclusions, and less than 5\% had a registered statistical analysis plan (e.g., planned analytical methods, pre-specified covariates). Confirmatory research was distinguished from exploratory work in roughly 40\% of reports. Reports published more recently (after 2015) had higher rates of transparency. Preventive intervention research needs to be more transparent. Since clearinghouses rely on robust findings to make well-informed decisions and researchers are incentivized to meet clearinghouse standards, clearinghouses should consider policies that encourage transparency to improve the credibility of evidence-based interventions.},
	number = {5},
	journal = {Prevention Science},
	author = {Buckley, Pamela R. and Ebersole, Charles R. and Steeger, Christine M. and Michaelson, Laura E. and Hill, Karl G. and Gardner, Frances},
	month = jul,
	year = {2022},
	pages = {787--798},
}

@article{christensen_transparency_2018,
	title = {Transparency, {Reproducibility}, and the {Credibility} of {Economics} {Research}},
	volume = {56},
	issn = {0022-0515},
	url = {https://www.aeaweb.org/articles?id=10.1257/jel.20171350},
	doi = {10.1257/jel.20171350},
	abstract = {There is growing interest in enhancing research transparency and reproducibility in economics and other scientific fields. We survey existing work on these topics within economics, and discuss the evidence suggesting that publication bias, inability to replicate, and specification searching remain widespread in the discipline. We next discuss recent progress in this area, including through improved research design, study registration and pre-analysis plans, disclosure standards, and open sharing of data and materials, drawing on experiences in both economics and other social sciences. We discuss areas where consensus is emerging on new practices, as well as approaches that remain controversial, and speculate about the most effective ways to make economics research more credible in the future.},
	language = {en},
	number = {3},
	urldate = {2023-11-30},
	journal = {Journal of Economic Literature},
	author = {Christensen, Garret and Miguel, Edward},
	month = sep,
	year = {2018},
	keywords = {Market for Economists, Methodological Issues: General, Higher Education, Research Institutions, Role of Economics, Role of Economists},
	pages = {920--980},
}
